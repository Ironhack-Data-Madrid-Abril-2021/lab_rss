{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with RSS Feeds Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of parsing RSS feeds and extracting information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in /Users/usuario/opt/anaconda3/lib/python3.8/site-packages (6.0.2)\n",
      "Requirement already satisfied: sgmllib3k in /Users/usuario/opt/anaconda3/lib/python3.8/site-packages (from feedparser) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use feedparser to parse the following RSS feed URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://feeds.feedburner.com/oreilly/radar/atom'\n",
    "\n",
    "radar =feedparser.parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Obtain a list of components (keys) that are available for this feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'title_detail', 'links', 'link', 'subtitle', 'subtitle_detail', 'updated', 'updated_parsed', 'language', 'sy_updateperiod', 'sy_updatefrequency', 'generator_detail', 'generator', 'feedburner_info', 'geo_lat', 'geo_long', 'feedburner_emailserviceid', 'feedburner_feedburnerhostname'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radar.feed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtain a list of components (keys) that are available for the *feed* component of this RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'title_detail', 'links', 'link', 'subtitle', 'subtitle_detail', 'updated', 'updated_parsed', 'language', 'sy_updateperiod', 'sy_updatefrequency', 'generator_detail', 'generator', 'feedburner_info', 'geo_lat', 'geo_long', 'feedburner_emailserviceid', 'feedburner_feedburnerhostname'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.feed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract and print the feed title, subtitle, author, and link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radar\n",
      "Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology\n",
      "https://www.oreilly.com/radar\n"
     ]
    }
   ],
   "source": [
    "print (reddit[\"feed\"][\"title\"])\n",
    "print (reddit[\"feed\"][\"subtitle\"])\n",
    "print  (reddit[\"feed\"][\"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike Loukides\n"
     ]
    }
   ],
   "source": [
    "first_entry = reddit[\"entries\"][0]['author']\n",
    "print (first_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCheapFakes\n",
      "DeepCheapFakes\n",
      "Radar trends to watch: May 2021\n",
      "Checking Jeff Bezos’s Math\n",
      "AI Adoption in the Enterprise 2021\n",
      "NFTs: Owning Digital Art\n",
      "Radar trends to watch: April 2021\n",
      "InfoTribes, Reality Brokers\n",
      "The End of Silicon Valley as We Know It?\n",
      "The Next Generation of AI\n",
      "Radar trends to watch: March 2021\n",
      "Product Management for AI\n",
      "5 things on our data and AI radar for 2021\n",
      "5 infrastructure and operations trends to watch in 2021\n",
      "The Wrong Question\n",
      "Radar trends to watch: February 2021\n",
      "Where Programming, Ops, AI, and the Cloud are Headed in 2021\n",
      "Seven Legal Questions for Data Scientists\n",
      "Patterns\n",
      "Radar trends to watch: January 2021\n",
      "Four short links: 14 Dec 2020\n",
      "Four short links: 8 Dec 2020\n",
      "O’Reilly’s top 20 live online training courses of 2020\n",
      "What is functional programming?\n",
      "Four short links: 4 Dec 2020\n",
      "Four short links: 1 Dec 2020\n",
      "Radar trends to watch: December 2020\n",
      "Four short links: 27 Nov 2020\n",
      "Four short links: 24 Nov 2020\n",
      "Four short links: 20 Nov 2020\n",
      "On Exactitude in Technical Debt\n",
      "Four short links: 17 Nov 2020\n",
      "Four short links: 13 Nov 2020\n",
      "Multi-Paradigm Languages\n",
      "Four short links: 10 November 2020\n",
      "Four short links: 6 Nov 2020\n",
      "Four short links: 4 Nov 2020\n",
      "Radar trends to watch: November 2020\n",
      "Four short links: 30 Oct 2020\n",
      "Four short links: 28 Oct 2020\n",
      "Our Favorite Questions\n",
      "Four short links: 21 Oct 2020\n",
      "Four Short Links: 16 October 2020\n",
      "Four short links: 14 Oct 2020\n",
      "AI Product Management After Deployment\n",
      "Four short links: 9 October 2020\n",
      "AI and Creativity\n",
      "Four short links: 6 October 2020\n",
      "Four short links: 2 October 2020\n",
      "Radar trends to watch: October 2020\n",
      "Four short links: 29 Sep 2020\n",
      "Four short links: 25 September 2020\n",
      "Four short links: 18 Sep 2020\n",
      "Four short links: 16 Sep 2020\n",
      "How to Set AI Goals\n",
      "Four short links: 11 Sep 2020\n",
      "Four short links: 9 Sep 2020\n",
      "Pair Programming with AI\n",
      "Four short links: 4 September 2020\n",
      "Four short links: 2 September 2020\n",
      "Radar trends to watch: September 2020\n"
     ]
    }
   ],
   "source": [
    "for i in reddit[\"entries\"]:\n",
    "   print (i ['title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count the number of entries that are contained in this RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit[\"entries\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Obtain a list of components (keys) available for an entry.\n",
    "\n",
    "*Hint: Remember to index first before requesting the keys*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'title_detail', 'links', 'link', 'comments', 'published', 'published_parsed', 'authors', 'author', 'author_detail', 'tags', 'id', 'guidislink', 'summary', 'summary_detail', 'content', 'wfw_commentrss', 'slash_comments', 'feedburner_origlink'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit['entries'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Extract a list of entry titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'DeepCheapFakes',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "  'value': 'DeepCheapFakes'},\n",
       " 'links': [{'rel': 'alternate',\n",
       "   'type': 'text/html',\n",
       "   'href': 'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/1pXDQUvNgxI/'}],\n",
       " 'link': 'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/1pXDQUvNgxI/',\n",
       " 'comments': 'https://www.oreilly.com/radar/deepcheapfakes/#respond',\n",
       " 'published': 'Tue, 11 May 2021 11:58:37 +0000',\n",
       " 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=11, tm_hour=11, tm_min=58, tm_sec=37, tm_wday=1, tm_yday=131, tm_isdst=0),\n",
       " 'authors': [{'name': 'Mike Loukides'}],\n",
       " 'author': 'Mike Loukides',\n",
       " 'author_detail': {'name': 'Mike Loukides'},\n",
       " 'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "  {'term': \"O'Reilly Insights\", 'scheme': None, 'label': None},\n",
       "  {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       " 'id': 'https://www.oreilly.com/radar/?p=13768',\n",
       " 'guidislink': False,\n",
       " 'summary': 'Back in 2019, Ben Lorica and I wrote about \\xa0deepfakes. Ben and I argued (in agreement with The Grugq and others in the infosec community) that the real danger wasn&#8217;t &#8220;Deep Fakes.&#8221; The real danger is cheap fakes, fakes that can be produced quickly, easily, in bulk, and at virtually no cost. Tactically, it makes [&#8230;]',\n",
       " 'summary_detail': {'type': 'text/html',\n",
       "  'language': None,\n",
       "  'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "  'value': 'Back in 2019, Ben Lorica and I wrote about \\xa0deepfakes. Ben and I argued (in agreement with The Grugq and others in the infosec community) that the real danger wasn&#8217;t &#8220;Deep Fakes.&#8221; The real danger is cheap fakes, fakes that can be produced quickly, easily, in bulk, and at virtually no cost. Tactically, it makes [&#8230;]'},\n",
       " 'content': [{'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "   'value': '<p>Back in 2019, Ben Lorica and I wrote about <a href=\"https://www.oreilly.com/radar/a-world-of-deepfakes/\">\\xa0deepfakes</a>. Ben and I argued (in agreement with <a href=\"https://medium.com/@thegrugq/cheap-fakes-beat-deep-fakes-b1ac91e44837\">The Grugq</a> and others in the infosec community) that the real danger wasn&#8217;t &#8220;Deep Fakes.&#8221; The real danger is cheap fakes, fakes that can be produced quickly, easily, in bulk, and at virtually no cost. Tactically, it makes little sense to spend money and time on expensive AI when people can be fooled in bulk much more cheaply.</p>\\n\\n\\n\\n<p>I don&#8217;t know if The Grugq has changed his thinking, but there was an obvious problem with that argument. What happens when deep fakes become cheap fakes? We&#8217;re seeing that: in the run up to the unionization vote at one of Amazon’s warehouses, there was a flood of <a href=\"https://www.technologyreview.com/2021/03/31/1021487/deepfake-amazon-workers-are-sowing-confusion-on-twitter-thats-not-the-problem/\">fake tweets defending Amazon&#8217;s work practices</a>. The Amazon tweets were probably a prank rather than misinformation seeded by Amazon; but they were still mass-produced.</p>\\n\\n\\n\\n<p>Similarly, four years ago, during the FCC’s public comment period for the elimination of net neutrality rules, large ISPs funded a campaign that generated nearly <a href=\"https://arstechnica.com/tech-policy/2021/05/biggest-isps-paid-for-8-5-million-fake-fcc-comments-opposing-net-neutrality/\">8.5 million fake comments</a>, out of a total of 22 million comments. Another 7.7 million comments were generated by a teenager.\\xa0 It’s unlikely that the ISPs hired humans to write all those fakes. (In fact, they <a href=\"https://ag.ny.gov/sites/default/files/oag-fakecommentsreport.pdf\">hired commercial “lead generators.”</a>) At that scale, using humans to generate fake comments wouldn’t be “cheap”; the New York State Attorney General’s office reports that the campaign cost US$8.2 million. And I’m sure the 19-year-old generating fake comments didn’t write them personally, or have the budget to pay others.</p>\\n\\n\\n\\n<p><a href=\"https://en.wikipedia.org/wiki/Natural-language_generation\">Natural language generation</a> technology has been around for a while. It’s seen fairly widespread commercial use since the mid-1990s, ranging from generating simple reports from data to generating sports stories from box scores. One company, <a href=\"https://automatedinsights.com/\">AutomatedInsights</a>, produces well over a billion pieces of content per year, and is <a href=\"https://en.wikipedia.org/wiki/Automated_Insights\">used by the Associated Press</a> to generate most of its corporate earnings stories. GPT and its successors raise the bar much higher. Although GPT-3’s first direct ancestors didn’t appear until 2018, it’s intriguing that <a href=\"https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)\">Transformers</a>, the technology on which GPT-3 is based, were introduced roughly a month after the comments started rolling in, and well before the comment period ended. It’s overreaching to guess that this technology was behind the massive attack on the public comment system–but it’s certainly indicative of a trend.\\xa0 And GPT-3 isn’t the only game in town; GPT-3 clones include products like <a href=\"https://contentyze.com/\">Contentyze</a> (which markets itself as an AI-enabled text editor) and EleutherAI&#8217;s <a href=\"https://www.eleuther.ai/projects/gpt-neo/\">GPT-Neo</a>.</p>\\n\\n\\n\\n<p>Generating fakes at scale isn’t just possible; it’s inexpensive.\\xa0 Much has been made of the cost of training GPT-3, <a href=\"https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/\">estimated at US$12 million</a>. If anything, this is a gross under-estimate that accounts for the electricity used, but not the cost of the hardware (or the human expertise). However, the economics of training a model are similar to the economics of building a new microprocessor: the first one off the production line costs a few billion dollars, the rest cost pennies. (Think about that when you buy your next laptop.) In <a href=\"https://chengh.medium.com/understand-the-pricing-of-gpt3-e646b2d63320#:~:text=For%20the%20%E2%80%9CCreate%E2%80%9D%20plan%2C,to%20selected%20users%20and%20applications.\">GPT-3’s pricing plan</a>, the heavy-duty Build tier costs US$400/month for 10 million “tokens.” Tokens are a measure of the output generated, in portions of a word. A good estimate is that a token is roughly 4 characters. A long-standing estimate for English text is that words average 5 characters, unless you’re faking an academic paper. So generating text costs about .005 cents ($0.00005) per word.\\xa0 Using the fake comments submitted to the FCC as a model, 8.5 million 20-word comments would cost $8,500 (or 0.1 cents/comment)–not much at all, and a bargain compared to $8.2 million. At the other end of the spectrum, you can get 10,000 tokens (enough for 8,000 words) for free.\\xa0 Whether for fun or for profit, generating deep fakes has become &#8220;cheap.&#8221;</p>\\n\\n\\n\\n<p>Are we at the mercy of sophisticated fakery? In MIT Technology Review’s <a href=\"https://www.technologyreview.com/2021/03/31/1021487/deepfake-amazon-workers-are-sowing-confusion-on-twitter-thats-not-the-problem/\">article</a> about the Amazon fakes, Sam Gregory points out that the solution isn&#8217;t careful analysis of images or text for tells; it&#8217;s to look for the obvious. New Twitter accounts, &#8220;reporters&#8221; who have never published an article you can find on Google, and other easily researchable facts are simple giveaways. It&#8217;s much simpler to research a reporter&#8217;s credentials than to judge whether or not the shadows in an image are correct, or whether the linguistic patterns in a text are borrowed from a corpus of training data. And, as Technology Review says, that kind of verification is more likely to be &#8220;robust to advances in deepfake technology.&#8221; As someone involved in electronic counter-espionage once told me, &#8220;non-existent people don&#8217;t cast a digital shadow.&#8221;</p>\\n\\n\\n\\n<p>However, it may be time to stop trusting digital shadows. Can automated fakery create a digital shadow?\\xa0 In the FCC case, many of the fake comments used the names of real people without their consent.\\xa0 The consent documentation was easily faked, too.\\xa0 GPT-3 makes many <a href=\"https://www.aiperspectives.com/gpt-3-does-not-understand/\">simple factual errors</a>–but so do humans. And unless you can automate it, fact-checking fake content is much more expensive than generating fake content.</p>\\n\\n\\n\\n<p>Deepfake technology will continue to get better and cheaper. Given that AI (and computing in general) is about scale, that may be the most important fact. Cheap fakes? If you only need one or two photoshopped images, it&#8217;s easy and inexpensive to create them by hand. You can even use <a href=\"https://www.gimp.org/\">gimp</a> if you don&#8217;t want to buy a Photoshop subscription. Likewise, if you need a few dozen tweets or facebook posts to seed confusion, it&#8217;s simple to write them by hand. For a few hundred, you can contract them out to Mechanical Turk. But at some point, scale is going to win out. If you want hundreds of fake images, <a href=\"https://thispersondoesnotexist.com/\">generating them with a neural network</a> is going to be cheaper. If you want fake texts by the hundreds of thousands, at some point a language model like GPT-3 or one of its clones is going to be cheaper. And I wouldn&#8217;t be surprised if researchers are also getting better at creating &#8220;digital shadows&#8221; for faked personas.</p>\\n\\n\\n\\n<p>Cheap fakes win, every time. But what happens when deepfakes become cheap fakes? What happens when the issue isn&#8217;t fakery by ones and twos, but fakery at scale? Fakery at Web scale is the problem we now face.</p>\\n<img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/1pXDQUvNgxI\" width=\"1\" />'}],\n",
       " 'wfw_commentrss': 'https://www.oreilly.com/radar/deepcheapfakes/feed/',\n",
       " 'slash_comments': '0',\n",
       " 'feedburner_origlink': 'https://www.oreilly.com/radar/deepcheapfakes/'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit['entries'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate the percentage of \"Four short links\" entry titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DeepCheapFakes', 'Radar trends to watch: May 2021', 'Checking Jeff Bezos’s Math', 'AI Adoption in the Enterprise 2021', 'NFTs: Owning Digital Art', 'Radar trends to watch: April 2021', 'InfoTribes, Reality Brokers', 'The End of Silicon Valley as We Know It?', 'The Next Generation of AI', 'Radar trends to watch: March 2021', 'Product Management for AI', '5 things on our data and AI radar for 2021', '5 infrastructure and operations trends to watch in 2021', 'The Wrong Question', 'Radar trends to watch: February 2021', 'Where Programming, Ops, AI, and the Cloud are Headed in 2021', 'Seven Legal Questions for Data Scientists', 'Patterns', 'Radar trends to watch: January 2021', 'Four short links: 14 Dec 2020', 'Four short links: 8 Dec 2020', 'O’Reilly’s top 20 live online training courses of 2020', 'What is functional programming?', 'Four short links: 4 Dec 2020', 'Four short links: 1 Dec 2020', 'Radar trends to watch: December 2020', 'Four short links: 27 Nov 2020', 'Four short links: 24 Nov 2020', 'Four short links: 20 Nov 2020', 'On Exactitude in Technical Debt', 'Four short links: 17 Nov 2020', 'Four short links: 13 Nov 2020', 'Multi-Paradigm Languages', 'Four short links: 10 November 2020', 'Four short links: 6 Nov 2020', 'Four short links: 4 Nov 2020', 'Radar trends to watch: November 2020', 'Four short links: 30 Oct 2020', 'Four short links: 28 Oct 2020', 'Our Favorite Questions', 'Four short links: 21 Oct 2020', 'Four Short Links: 16 October 2020', 'Four short links: 14 Oct 2020', 'AI Product Management After Deployment', 'Four short links: 9 October 2020', 'AI and Creativity', 'Four short links: 6 October 2020', 'Four short links: 2 October 2020', 'Radar trends to watch: October 2020', 'Four short links: 29 Sep 2020', 'Four short links: 25 September 2020', 'Four short links: 18 Sep 2020', 'Four short links: 16 Sep 2020', 'How to Set AI Goals', 'Four short links: 11 Sep 2020', 'Four short links: 9 Sep 2020', 'Pair Programming with AI', 'Four short links: 4 September 2020', 'Four short links: 2 September 2020', 'Radar trends to watch: September 2020']\n"
     ]
    }
   ],
   "source": [
    "titles = [reddit.entries[i].title for i in range(len(reddit.entries))]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Create a Pandas data frame from the feed's entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>comments</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>tags</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>content</th>\n",
       "      <th>wfw_commentrss</th>\n",
       "      <th>slash_comments</th>\n",
       "      <th>feedburner_origlink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepCheapFakes</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>http://feedproxy.google.com/~r/oreilly/radar/a...</td>\n",
       "      <td>https://www.oreilly.com/radar/deepcheapfakes/#...</td>\n",
       "      <td>Tue, 11 May 2021 11:58:37 +0000</td>\n",
       "      <td>(2021, 5, 11, 11, 58, 37, 1, 131, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "      <td>[{'term': 'Artificial Intelligence', 'scheme':...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=13768</td>\n",
       "      <td>False</td>\n",
       "      <td>Back in 2019, Ben Lorica and I wrote about  de...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/deepcheapfakes/f...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.oreilly.com/radar/deepcheapfakes/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radar trends to watch: May 2021</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>http://feedproxy.google.com/~r/oreilly/radar/a...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>Mon, 03 May 2021 14:05:40 +0000</td>\n",
       "      <td>(2021, 5, 3, 14, 5, 40, 0, 123, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "      <td>[{'term': 'Radar Trends', 'scheme': None, 'lab...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=13755</td>\n",
       "      <td>False</td>\n",
       "      <td>We’ll start with a moment of silence. RIP Dan ...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Checking Jeff Bezos’s Math</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>http://feedproxy.google.com/~r/oreilly/radar/a...</td>\n",
       "      <td>https://www.oreilly.com/radar/checking-jeff-be...</td>\n",
       "      <td>Fri, 23 Apr 2021 20:43:28 +0000</td>\n",
       "      <td>(2021, 4, 23, 20, 43, 28, 4, 113, 0)</td>\n",
       "      <td>[{'name': 'Tim O’Reilly'}]</td>\n",
       "      <td>Tim O’Reilly</td>\n",
       "      <td>{'name': 'Tim O’Reilly'}</td>\n",
       "      <td>[{'term': 'Business', 'scheme': None, 'label':...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=13748</td>\n",
       "      <td>False</td>\n",
       "      <td>“If you want to be successful in business (in ...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/checking-jeff-be...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.oreilly.com/radar/checking-jeff-be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI Adoption in the Enterprise 2021</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>http://feedproxy.google.com/~r/oreilly/radar/a...</td>\n",
       "      <td>https://www.oreilly.com/radar/ai-adoption-in-t...</td>\n",
       "      <td>Mon, 19 Apr 2021 12:20:38 +0000</td>\n",
       "      <td>(2021, 4, 19, 12, 20, 38, 0, 109, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "      <td>[{'term': 'AI &amp; ML', 'scheme': None, 'label': ...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=13720</td>\n",
       "      <td>False</td>\n",
       "      <td>During the first weeks of February, we asked r...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/ai-adoption-in-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.oreilly.com/radar/ai-adoption-in-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFTs: Owning Digital Art</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>http://feedproxy.google.com/~r/oreilly/radar/a...</td>\n",
       "      <td>https://www.oreilly.com/radar/nfts-owning-digi...</td>\n",
       "      <td>Tue, 06 Apr 2021 18:43:26 +0000</td>\n",
       "      <td>(2021, 4, 6, 18, 43, 26, 1, 96, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "      <td>[{'term': 'Building a data culture', 'scheme':...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=13713</td>\n",
       "      <td>False</td>\n",
       "      <td>It would be hard to miss the commotion around ...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/nfts-owning-digi...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.oreilly.com/radar/nfts-owning-digi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                      DeepCheapFakes   \n",
       "1     Radar trends to watch: May 2021   \n",
       "2          Checking Jeff Bezos’s Math   \n",
       "3  AI Adoption in the Enterprise 2021   \n",
       "4            NFTs: Owning Digital Art   \n",
       "\n",
       "                                        title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                               links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "4  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://feedproxy.google.com/~r/oreilly/radar/a...   \n",
       "1  http://feedproxy.google.com/~r/oreilly/radar/a...   \n",
       "2  http://feedproxy.google.com/~r/oreilly/radar/a...   \n",
       "3  http://feedproxy.google.com/~r/oreilly/radar/a...   \n",
       "4  http://feedproxy.google.com/~r/oreilly/radar/a...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  https://www.oreilly.com/radar/deepcheapfakes/#...   \n",
       "1  https://www.oreilly.com/radar/radar-trends-to-...   \n",
       "2  https://www.oreilly.com/radar/checking-jeff-be...   \n",
       "3  https://www.oreilly.com/radar/ai-adoption-in-t...   \n",
       "4  https://www.oreilly.com/radar/nfts-owning-digi...   \n",
       "\n",
       "                         published                      published_parsed  \\\n",
       "0  Tue, 11 May 2021 11:58:37 +0000  (2021, 5, 11, 11, 58, 37, 1, 131, 0)   \n",
       "1  Mon, 03 May 2021 14:05:40 +0000    (2021, 5, 3, 14, 5, 40, 0, 123, 0)   \n",
       "2  Fri, 23 Apr 2021 20:43:28 +0000  (2021, 4, 23, 20, 43, 28, 4, 113, 0)   \n",
       "3  Mon, 19 Apr 2021 12:20:38 +0000  (2021, 4, 19, 12, 20, 38, 0, 109, 0)   \n",
       "4  Tue, 06 Apr 2021 18:43:26 +0000    (2021, 4, 6, 18, 43, 26, 1, 96, 0)   \n",
       "\n",
       "                       authors         author              author_detail  \\\n",
       "0  [{'name': 'Mike Loukides'}]  Mike Loukides  {'name': 'Mike Loukides'}   \n",
       "1  [{'name': 'Mike Loukides'}]  Mike Loukides  {'name': 'Mike Loukides'}   \n",
       "2   [{'name': 'Tim O’Reilly'}]   Tim O’Reilly   {'name': 'Tim O’Reilly'}   \n",
       "3  [{'name': 'Mike Loukides'}]  Mike Loukides  {'name': 'Mike Loukides'}   \n",
       "4  [{'name': 'Mike Loukides'}]  Mike Loukides  {'name': 'Mike Loukides'}   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'term': 'Artificial Intelligence', 'scheme':...   \n",
       "1  [{'term': 'Radar Trends', 'scheme': None, 'lab...   \n",
       "2  [{'term': 'Business', 'scheme': None, 'label':...   \n",
       "3  [{'term': 'AI & ML', 'scheme': None, 'label': ...   \n",
       "4  [{'term': 'Building a data culture', 'scheme':...   \n",
       "\n",
       "                                       id  guidislink  \\\n",
       "0  https://www.oreilly.com/radar/?p=13768       False   \n",
       "1  https://www.oreilly.com/radar/?p=13755       False   \n",
       "2  https://www.oreilly.com/radar/?p=13748       False   \n",
       "3  https://www.oreilly.com/radar/?p=13720       False   \n",
       "4  https://www.oreilly.com/radar/?p=13713       False   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Back in 2019, Ben Lorica and I wrote about  de...   \n",
       "1  We’ll start with a moment of silence. RIP Dan ...   \n",
       "2  “If you want to be successful in business (in ...   \n",
       "3  During the first weeks of February, we asked r...   \n",
       "4  It would be hard to miss the commotion around ...   \n",
       "\n",
       "                                      summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base'...   \n",
       "1  {'type': 'text/html', 'language': None, 'base'...   \n",
       "2  {'type': 'text/html', 'language': None, 'base'...   \n",
       "3  {'type': 'text/html', 'language': None, 'base'...   \n",
       "4  {'type': 'text/html', 'language': None, 'base'...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [{'type': 'text/html', 'language': None, 'base...   \n",
       "1  [{'type': 'text/html', 'language': None, 'base...   \n",
       "2  [{'type': 'text/html', 'language': None, 'base...   \n",
       "3  [{'type': 'text/html', 'language': None, 'base...   \n",
       "4  [{'type': 'text/html', 'language': None, 'base...   \n",
       "\n",
       "                                      wfw_commentrss slash_comments  \\\n",
       "0  https://www.oreilly.com/radar/deepcheapfakes/f...              0   \n",
       "1  https://www.oreilly.com/radar/radar-trends-to-...              0   \n",
       "2  https://www.oreilly.com/radar/checking-jeff-be...              0   \n",
       "3  https://www.oreilly.com/radar/ai-adoption-in-t...              0   \n",
       "4  https://www.oreilly.com/radar/nfts-owning-digi...              0   \n",
       "\n",
       "                                 feedburner_origlink  \n",
       "0      https://www.oreilly.com/radar/deepcheapfakes/  \n",
       "1  https://www.oreilly.com/radar/radar-trends-to-...  \n",
       "2  https://www.oreilly.com/radar/checking-jeff-be...  \n",
       "3  https://www.oreilly.com/radar/ai-adoption-in-t...  \n",
       "4  https://www.oreilly.com/radar/nfts-owning-digi...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(reddit.entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Count the number of entries per author and sort them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nat Torkington</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tim O’Reilly</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Castrounis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugo Bowne-Anderson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Justin Norman and Mike Loukides</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevlin Henney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Patrick Hall and Ayoub Ouederni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q Ethan McCallum, Chris Butler and Shane Glynn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           author  entries\n",
       "6                                  Nat Torkington       27\n",
       "5                                   Mike Loukides       21\n",
       "0                                                        4\n",
       "9                                    Tim O’Reilly        2\n",
       "1                                 Alex Castrounis        1\n",
       "2                             Hugo Bowne-Anderson        1\n",
       "3                 Justin Norman and Mike Loukides        1\n",
       "4                                   Kevlin Henney        1\n",
       "7                 Patrick Hall and Ayoub Ouederni        1\n",
       "8  Q Ethan McCallum, Chris Butler and Shane Glynn        1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = df.groupby('author', as_index=False).agg({'title':'count'})\n",
    "authors.columns = ['author', 'entries']\n",
    "authors.sort_values('entries', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Add a new column to the data frame that contains the length (number of characters) of each entry title. Return a data frame that contains the title, author, and title length of each entry in descending order (longest title length at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_length'] = df['title'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Create a list of entry titles whose summary includes the phrase \"machine learning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Where Programming, Ops, AI, and the Cloud are ...</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5 infrastructure and operations trends to watc...</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>O’Reilly’s top 20 live online training courses...</td>\n",
       "      <td></td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5 things on our data and AI radar for 2021</td>\n",
       "      <td></td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Seven Legal Questions for Data Scientists</td>\n",
       "      <td>Patrick Hall and Ayoub Ouederni</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "15  Where Programming, Ops, AI, and the Cloud are ...   \n",
       "12  5 infrastructure and operations trends to watc...   \n",
       "21  O’Reilly’s top 20 live online training courses...   \n",
       "11         5 things on our data and AI radar for 2021   \n",
       "16          Seven Legal Questions for Data Scientists   \n",
       "\n",
       "                             author  title_length  \n",
       "15                    Mike Loukides            60  \n",
       "12                                             55  \n",
       "21                                             54  \n",
       "11                                             42  \n",
       "16  Patrick Hall and Ayoub Ouederni            41  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title', 'author', 'title_length']].sort_values('title_length', ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
